{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec8f842-6f7b-4a18-87ee-914243078f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "csv_file = \"C:/Users/Gurkanwal Singh/Documents/DOUGLAS SEM6/Adv Topics in Data Analytics/all_stocks_5yr.csv\"\n",
    "\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92567ab4-5bb7-4fee-9716-ef3e3600d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scale  CSV Write Time (s)  CSV Read Time (s)  Parquet Write Time (s)  \\\n",
      "0    1x                1.45               0.26                    0.25   \n",
      "1   10x               19.75               3.62                    2.75   \n",
      "2  100x              227.02              41.40                   31.29   \n",
      "\n",
      "   Parquet Read Time (s)  CSV File Size (MB)  Parquet File Size (MB)  \n",
      "0                   0.09               28.80                   10.15  \n",
      "1                   0.82              288.01                   95.35  \n",
      "2                  10.31             2880.05                  951.71  \n"
     ]
    }
   ],
   "source": [
    "# Function to scale dataset\n",
    "def expand_dataset(df, multiplier):\n",
    "    return pd.concat([df.copy() for _ in range(multiplier)], ignore_index=True)\n",
    "\n",
    "# Define scaling factors\n",
    "scaling_factors = [1, 10, 100]\n",
    "labels = [\"1x\", \"10x\", \"100x\"]\n",
    "benchmark_data = []\n",
    "\n",
    "# Run benchmarking tests\n",
    "for factor, tag in zip(scaling_factors, labels):\n",
    "    dataset_expanded = data if factor == 1 else expand_dataset(data, factor)\n",
    "    \n",
    "    # File paths\n",
    "    csv_file = f\"C:/Users/Gurkanwal Singh/Documents/DOUGLAS SEM6/Adv Topics in Data Analytics/data_{tag}.csv\"\n",
    "    parquet_file = f\"C:/Users/Gurkanwal Singh/Documents/DOUGLAS SEM6/Adv Topics in Data Analytics/data_{tag}.parquet\"\n",
    "    \n",
    "    # Measure CSV write speed\n",
    "    start_time = time.time()\n",
    "    dataset_expanded.to_csv(csv_file, index=False)\n",
    "    csv_write_duration = time.time() - start_time\n",
    "    \n",
    "    # Measure CSV read speed\n",
    "    start_time = time.time()\n",
    "    pd.read_csv(csv_file)\n",
    "    csv_read_duration = time.time() - start_time\n",
    "    \n",
    "    # Measure Parquet write speed\n",
    "    start_time = time.time()\n",
    "    dataset_expanded.to_parquet(parquet_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n",
    "    parquet_write_duration = time.time() - start_time\n",
    "    \n",
    "    # Measure Parquet read speed\n",
    "    start_time = time.time()\n",
    "    pd.read_parquet(parquet_file, engine=\"pyarrow\")\n",
    "    parquet_read_duration = time.time() - start_time\n",
    "    \n",
    "    # Get file sizes\n",
    "    csv_file_size = os.path.getsize(csv_file) / (1024 * 1024)  # Convert bytes to MB\n",
    "    parquet_file_size = os.path.getsize(parquet_file) / (1024 * 1024)\n",
    "    \n",
    "    # Store results\n",
    "    benchmark_data.append({\n",
    "        \"Scale\": tag,\n",
    "        \"CSV Write Time (s)\": round(csv_write_duration, 2),\n",
    "        \"CSV Read Time (s)\": round(csv_read_duration, 2),\n",
    "        \"Parquet Write Time (s)\": round(parquet_write_duration, 2),\n",
    "        \"Parquet Read Time (s)\": round(parquet_read_duration, 2),\n",
    "        \"CSV File Size (MB)\": round(csv_file_size, 2),\n",
    "        \"Parquet File Size (MB)\": round(parquet_file_size, 2)\n",
    "    })\n",
    "    \n",
    "# Convert to DataFrame for display\n",
    "benchmark_results_df = pd.DataFrame(benchmark_data)\n",
    "print(benchmark_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34caa1b6-def5-4a0c-8ed1-62221c383799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
